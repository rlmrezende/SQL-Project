# Final-Project-Transforming-and-Analyzing-Data-with-SQL

## Project/Goals
Import CSV ecommerce spreadsheets into PostgreSQL for data analysis.

## Process
### 1. Identify the data types for each column in the spreadsheets.
### 2. Manually create tables in PostgreSQL with respective columns for all five spreadsheets.
### 3. Use the COPY query to import the data from the CSV files into the corresponding tables.
### 4. Checking for null values in the imported data and handling them appropriately.
### 5. Validate the imported data to ensure data integrity and consistency.


## Results
The importation of all five ecommerce spreadsheets into the PostgreSQL database was successful. However, ensuring data quality proved to be a big challenging task.

During the data cleaning process, duplicate and null values were identified and removed appropriately. Unnecessary columns were also identified and removed to simplify the tables and reduce the risk of errors. Primary keys and foreign keys were assigned to create an ERD to establish relationships between tables and ensure data integrity.

Despite these efforts, achieving good data quality required extensive manual work to clean the raw data, including data comparisons and corrections to ensure consistency.

## Challenges 
### 1. Checking the correct data types for each column in the spreadsheets.
### 2. Checking for duplicates and null values in the imported data and handling them appropriately to ensure data quality.
### 3. Identifying unnecessary columns and removing them to clean the data for efficient analysis.
### 4. Ensuring data integrity and consistency after making changes to the data.
### 5. Finding relationships between tables and assigning primary keys and foreign keys to create an ERD.


## Future Goals
### 1. Set correct values for all NULL data to improve data understanding and analysis.
### 2. Continue data comparison to identify and adjust or simplify the tables for more efficient analysis.
### 3. Remove more unnecessary data to further clean the data.
### 4. Seek better data quality by bringing robustness to the analysis using advanced statistical techniques.
### 5. Ensure the integrity and consistency of the data so that it is reliable.
